{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple networks\n",
    "\n",
    "So far we've been querying a single model. We'll extend our database schema to\n",
    "allow multiple models to be stored and queried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The models\n",
    "\n",
    "We'll take our tried-and-trusted function from earlier notebooks, and train 2\n",
    "different networks on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.duckdb as db\n",
    "import utils.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(223)\n",
    "\n",
    "def f(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    elif 0 <= x < 5:\n",
    "        return x\n",
    "    elif 5 <= x < 10:\n",
    "        return 10-x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "x_train = np.linspace(-5, 15, 1000)\n",
    "y_train = np.array([f(x) for x in x_train])\n",
    "\n",
    "model1 = nn.ReLUFNN(input_size=1, hidden_size=2, num_hidden_layers=2, output_size=1)\n",
    "nn.train(model1, x_train, y_train, save_path=\"models/eval_multiple_networks1.pt\")\n",
    "\n",
    "model2 = nn.ReLUFNN(input_size=1, hidden_size=3, num_hidden_layers=3, output_size=1)\n",
    "nn.train(model2, x_train, y_train, save_path=\"models/eval_multiple_networks2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The database\n",
    "\n",
    "We'll construct our database as usual, but include an extra column to specify\n",
    "which model the nodes/edges belong to.\n",
    "\n",
    "First, we reset the database to make sure we start from a clean slate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7878f1d41e70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.con.execute(\"DROP TABLE IF EXISTS edge\")\n",
    "db.con.execute(\"DROP TABLE IF EXISTS node\")\n",
    "db.con.execute(\"DROP TABLE IF EXISTS model\")\n",
    "\n",
    "db.con.execute(\"DROP SEQUENCE IF EXISTS seq_node\")\n",
    "db.con.execute(\"CREATE SEQUENCE seq_node START 1\")\n",
    "\n",
    "db.con.execute(\"DROP SEQUENCE IF EXISTS seq_model\")\n",
    "db.con.execute(\"CREATE SEQUENCE seq_model START 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a table to hold our model metadata. In this case, we simply\n",
    "keep the name of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7878f1d41e70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE model(\n",
    "        id INTEGER PRIMARY KEY DEFAULT NEXTVAL('seq_model'),\n",
    "        name TEXT\n",
    "    )\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we'll create the node/edge tables, with the extra column to reference\n",
    "the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7878f1d41e70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE node(\n",
    "        id INTEGER PRIMARY KEY DEFAULT NEXTVAL('seq_node'),\n",
    "        model_id INTEGER,\n",
    "        bias REAL,\n",
    "        name TEXT,\n",
    "        FOREIGN KEY (model_id) REFERENCES model(id)\n",
    "    )\"\"\"\n",
    ")\n",
    "db.con.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE edge(\n",
    "        model_id INTEGER,\n",
    "        src INTEGER,\n",
    "        dst INTEGER,\n",
    "        weight REAL,\n",
    "        FOREIGN KEY (model_id) REFERENCES model(id),\n",
    "        FOREIGN KEY (src) REFERENCES node(id),\n",
    "        FOREIGN KEY (dst) REFERENCES node(id),\n",
    "    )\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting the models\n",
    "\n",
    "To insert the models into the database, we'll recycle our [utility\n",
    "code](./utils/duckdb.py), but make sure to add the `model_id` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "\n",
    "def load_model_into_db(model, name):\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    # Insert the model\n",
    "    result = db.con.execute(\n",
    "        \"INSERT INTO model (name) VALUES ($name) RETURNING (id)\",\n",
    "        {\"name\": name}\n",
    "    )\n",
    "\n",
    "    (model_id,) = result.fetchone()\n",
    "    node_ids = [[]]\n",
    "\n",
    "    def nodes(node_ids):\n",
    "        global id\n",
    "        # Retrieves the input x weights matrix\n",
    "        input_weights = list(state_dict.items())[0][1].tolist()\n",
    "        num_input_nodes = len(input_weights[0])\n",
    "\n",
    "        for i in range(0, num_input_nodes):\n",
    "            id += 1\n",
    "            yield [id, model_id, 0, f\"input.{i}\"]\n",
    "            node_ids[0].append(id)\n",
    "\n",
    "        layer = 0\n",
    "        # In the first pass, insert all nodes with their biases\n",
    "        for name, values in state_dict.items():\n",
    "            # state_dict alternates between weight and bias tensors.\n",
    "            if not \"bias\" in name:\n",
    "                continue\n",
    "\n",
    "            node_ids.append([])\n",
    "\n",
    "            layer += 1\n",
    "            for i, bias in enumerate(values.tolist()):\n",
    "                id += 1\n",
    "                yield [id, model_id, bias, f\"{name}.{i}\"]\n",
    "                node_ids[layer].append(id)\n",
    "\n",
    "    def edges(node_ids):\n",
    "        # In the second pass, insert all edges and their weights. This assumes a fully\n",
    "        # connected network.\n",
    "        layer = 0\n",
    "        for name, values in state_dict.items():\n",
    "            # state_dict alternates between weight and bias tensors.\n",
    "            if not \"weight\" in name:\n",
    "                continue\n",
    "\n",
    "            # Each weight tensor has a list for each node in the next layer. The\n",
    "            # elements of this list correspond to the nodes of the current layer.\n",
    "            weight_tensor = values.tolist()\n",
    "            for from_index, from_node in enumerate(node_ids[layer]):\n",
    "                for to_index, to_node in enumerate(node_ids[layer + 1]):\n",
    "                    weight = weight_tensor[to_index][from_index]\n",
    "                    yield [model_id, from_node, to_node, weight]\n",
    "\n",
    "            layer += 1\n",
    "\n",
    "    db.batch_insert(nodes(node_ids), \"node\")\n",
    "    db.batch_insert(edges(node_ids), \"edge\")\n",
    "\n",
    "    db.con.execute(f\"EXPORT DATABASE 'dbs/multiple_networks.db'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_into_db(model1, \"Model 1\")\n",
    "load_model_into_db(model2, \"Model 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the database\n",
    "\n",
    "We can now do queries across multiple models. As a basic example, let's run the\n",
    "`eval` query for all models in the database for a given input. We'll give the\n",
    "full query here, with comments for our adaptations.\n",
    "\n",
    "```sql\n",
    "WITH RECURSIVE input_values_single AS (\n",
    "    -- We do a hardcoded query with 5 as the input value, but this could come \n",
    "    -- from anywhere.\n",
    "    SELECT 0 AS input_set_id, 1 AS input_node_idx, 5 AS input_value\n",
    "),\n",
    "-- We make sure we have a separate input_value entry for each model in the\n",
    "-- database by doing a cross join.\n",
    "input_values AS (\n",
    "    SELECT m.id AS model_id, input_set_id, input_node_idx, input_value\n",
    "    FROM input_values_single\n",
    "    CROSS JOIN model m\n",
    "),\n",
    "input_nodes AS (\n",
    "    SELECT\n",
    "        model_id,\n",
    "        id,\n",
    "        -- We add a PARTITION BY to make sure the row number increments\n",
    "        -- separately per model.\n",
    "        ROW_NUMBER() OVER (PARTITION BY model_id ORDER BY id) AS input_node_idx\n",
    "    FROM node\n",
    "    WHERE id NOT IN\n",
    "    (SELECT dst FROM edge)\n",
    "),\n",
    "output_nodes AS (\n",
    "    SELECT model_id, id\n",
    "    FROM node\n",
    "    WHERE id NOT IN\n",
    "    (SELECT src FROM edge)\n",
    "),\n",
    "tx AS (\n",
    "    SELECT\n",
    "        -- Add the model ID for disambiguation.\n",
    "        i.model_id,\n",
    "        v.input_set_id AS input_set_id,\n",
    "        GREATEST(\n",
    "            0,\n",
    "            n.bias + SUM(e.weight * v.input_value)\n",
    "        ) AS value,\n",
    "        e.dst AS id\n",
    "    FROM edge e\n",
    "    JOIN input_nodes i ON i.id = e.src\n",
    "    JOIN node n ON e.dst = n.id\n",
    "    -- Join on the correct input value.\n",
    "    JOIN input_values v ON i.input_node_idx = v.input_node_idx AND v.model_id = i.model_id\n",
    "    GROUP BY i.model_id, e.dst, n.bias, v.input_set_id\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT\n",
    "        tx.model_id,\n",
    "        tx.input_set_id AS input_set_id,\n",
    "        GREATEST(\n",
    "            0,\n",
    "            n.bias + SUM(e.weight * tx.value)\n",
    "        ) AS value,\n",
    "        e.dst AS id\n",
    "    FROM edge e\n",
    "    JOIN tx ON tx.id = e.src AND tx.model_id = e.model_id\n",
    "    JOIN node n ON e.dst = n.id\n",
    "    GROUP BY tx.model_id, e.dst, n.bias, tx.input_set_id\n",
    "),\n",
    "t_out AS (\n",
    "    SELECT\n",
    "        -- And add the model ID to the output as well, so we know which model\n",
    "        -- gave each value.\n",
    "        tx.model_id,\n",
    "        tx.input_set_id AS input_set_id,\n",
    "        n.bias + SUM(e.weight * tx.value) AS value,\n",
    "        e.dst AS id\n",
    "    FROM edge e\n",
    "    JOIN output_nodes o ON e.dst = o.id\n",
    "    JOIN node n ON o.id = n.id\n",
    "    JOIN tx ON tx.id = e.src AND tx.model_id = e.model_id\n",
    "    GROUP BY tx.model_id, e.dst, n.bias, tx.input_set_id\n",
    ")\n",
    "-- Include some model metadata\n",
    "SELECT m.name, t.value AS output_value\n",
    "FROM model m\n",
    "JOIN t_out t ON t.model_id = m.id;\n",
    "```\n",
    "\n",
    "This query is the same as the one in\n",
    "[eval_recursive_multiple_models.sql](./queries/eval_recursive_multiple_models.sql).\n",
    "Let's execute it and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┬────────────────────┐\n",
       "│  name   │    output_value    │\n",
       "│ varchar │       double       │\n",
       "├─────────┼────────────────────┤\n",
       "│ Model 1 │   4.99999148441685 │\n",
       "│ Model 2 │ 1.2487479448318481 │\n",
       "└─────────┴────────────────────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('queries/eval_recursive_multiple_models.sql') as file:\n",
    "    query = file.read()\n",
    "\n",
    "db.con.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.0000], grad_fn=<ViewBackward0>)\n",
      "tensor([1.2487], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "print(model1(torch.tensor([5.0])))\n",
    "print(model2(torch.tensor([5.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are correct. This simple eval query could already be useful to see\n",
    "which models have the best results for a given input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

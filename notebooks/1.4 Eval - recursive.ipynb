{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive queries\n",
    "\n",
    "Up until now we stayed true to the paper and added a CTE for each layer in the\n",
    "neural network. In this chapter, we'll leverage SQL's recursive capabilities to\n",
    "create a query that works for every FNN, without needing to know the number of\n",
    "hidden layers beforehand. In fact, we know next to nothing about the networks we\n",
    "query. They can have:\n",
    "\n",
    "- An unknown number of input neurons\n",
    "- An unknown number of output neurons\n",
    "- An unknown number of hidden layers\n",
    "- An unknown number of neurons in each hidden layer\n",
    "\n",
    "## The network\n",
    "\n",
    "To show we don't need to know anything about the neural network, we'll create\n",
    "one with randomized properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import utils.duckdb as db\n",
    "import pandas as pd\n",
    "import utils.nn as nn\n",
    "import random\n",
    "\n",
    "torch.manual_seed(223)\n",
    "random.seed(223)\n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "input_size = random.randint(1, 10)\n",
    "output_size = random.randint(1, 10)\n",
    "\n",
    "x_train = torch.randn(num_samples, input_size) * 100\n",
    "y_train = torch.randn(num_samples, output_size) * 10\n",
    "\n",
    "model = nn.ReLUFNN(\n",
    "    input_size=input_size,\n",
    "    output_size=output_size,\n",
    "    hidden_size=random.randint(3, 10),\n",
    "    num_hidden_layers=random.randint(2, 20)\n",
    ")\n",
    "nn.train(model, x_train, y_train, save_path=\"models/eval_recursive.pt\")\n",
    "\n",
    "db.load_pytorch_model_into_db(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look closely at the code above, you'll see that we traded in SQLite for\n",
    "DuckDB. The corresponding module can be found [here](./utils/duckdb.py).\n",
    "\n",
    "Previously, we used SQLite because DuckDB's performance suffers when\n",
    "constructing large queries, as we've done so far. We now opt for DuckDB because\n",
    "the recursive variant actually performs comparably to SQLite, and more primarily\n",
    "because SQLite does not support aggregations in recursive queries, which our\n",
    "query relies on.\n",
    "\n",
    "Some more discussion on this topic can be found in a [separate\n",
    "chapter](./A.1%20Aside%20-%20DuckDB%20bugreport)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The query\n",
    "\n",
    "The full query is given as follows:\n",
    "\n",
    "```sql\n",
    "WITH RECURSIVE input_values AS (\n",
    "    SELECT ? AS input_set_id, ? AS input_node_idx, ? AS input_value\n",
    "    UNION\n",
    "    SELECT ? AS input_set_id, ? AS input_node_idx, ? AS input_value\n",
    "),\n",
    "input_nodes AS (\n",
    "    SELECT\n",
    "        id,\n",
    "        bias,\n",
    "        ROW_NUMBER() OVER (ORDER BY id) AS input_node_idx\n",
    "    FROM node\n",
    "    WHERE id NOT IN\n",
    "    (SELECT dst FROM edge)\n",
    "),\n",
    "output_nodes AS (\n",
    "    SELECT id\n",
    "    FROM node\n",
    "    WHERE id NOT IN\n",
    "    (SELECT src FROM edge)\n",
    "),\n",
    "tx AS (\n",
    "    -- Base case (t1)\n",
    "    SELECT\n",
    "        v.input_set_id AS input_set_id,\n",
    "        GREATEST(\n",
    "            0,\n",
    "            n.bias + SUM(e.weight * v.input_value)\n",
    "        ) AS value,\n",
    "        e.dst AS id\n",
    "    FROM edge e\n",
    "    JOIN input_nodes i ON i.id = e.src\n",
    "    JOIN node n ON e.dst = n.id\n",
    "    JOIN input_values v ON i.input_node_idx = v.input_node_idx\n",
    "    GROUP BY e.dst, n.bias, v.input_set_id\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Recursive case\n",
    "    SELECT\n",
    "        tx.input_set_id AS input_set_id,\n",
    "        GREATEST(\n",
    "            0,\n",
    "            n.bias + SUM(e.weight * tx.value)\n",
    "        ) AS value,\n",
    "        e.dst AS id\n",
    "    FROM edge e\n",
    "    JOIN tx ON tx.id = e.src\n",
    "    JOIN node n ON e.dst = n.id\n",
    "    GROUP BY e.dst, n.bias, tx.input_set_id\n",
    "),\n",
    "-- As the last step, repeat the calculation for the output nodes, but omit the\n",
    "-- ReLU this time (per definition)\n",
    "t_out AS (\n",
    "    SELECT\n",
    "        tx.input_set_id AS input_set_id,\n",
    "        n.bias + SUM(e.weight * tx.value) AS value,\n",
    "        e.dst AS id\n",
    "    FROM edge e\n",
    "    JOIN output_nodes o ON e.dst = o.id\n",
    "    JOIN node n ON o.id = n.id\n",
    "    JOIN tx ON tx.id = e.src\n",
    "    GROUP BY e.dst, n.bias, tx.input_set_id\n",
    ")\n",
    "SELECT * FROM t_out ORDER BY id;\n",
    "```\n",
    "\n",
    "This query is very similar to what we ended up with in the previous chapter. The\n",
    "key differences are:\n",
    "\n",
    "- We use `WITH RECURSIVE` to indicate some CTEs use recursion.\n",
    "- We add a query that fetches the set of output nodes. These are all nodes that\n",
    "  do not have an outgoing edge.\n",
    "- The recursive CTE in question is `tx`, which is split in a base case and a\n",
    "  recursion step.\n",
    "- The base case corresponds to $t_1$ of the FO(SUM) term.\n",
    "- The recursion step corresponds to the term $t_l$.\n",
    "- When we calculate $t_{out}$, we join on the set of output nodes, since these are\n",
    "  the only values we are ultimately interested in.\n",
    "\n",
    "Translating this query to code is straightforward. We copy it as-is, only adding\n",
    "some logic to specify the input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_nn(input_value):\n",
    "    input_clauses = []\n",
    "    for input_set, input in enumerate(input_value):\n",
    "        for i,_ in enumerate(input):\n",
    "            input_clauses.append(f\"\"\"\n",
    "                SELECT\n",
    "                    {input_set} AS input_set_id,\n",
    "                    {i + 1} AS input_node_idx,\n",
    "                    ? AS input_value\n",
    "            \"\"\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "        WITH RECURSIVE input_values AS (\n",
    "            {\" UNION \".join(input_clauses)}\n",
    "        ),\n",
    "        input_nodes AS (\n",
    "            SELECT\n",
    "                id,\n",
    "                bias,\n",
    "                ROW_NUMBER() OVER (ORDER BY id) AS input_node_idx\n",
    "            FROM node\n",
    "            WHERE id NOT IN\n",
    "            (SELECT dst FROM edge)\n",
    "        ),\n",
    "        output_nodes AS (\n",
    "            SELECT id\n",
    "            FROM node\n",
    "            WHERE id NOT IN\n",
    "            (SELECT src FROM edge)\n",
    "        ),\n",
    "        tx AS (\n",
    "            -- Base case (t1)\n",
    "            SELECT\n",
    "                v.input_set_id AS input_set_id,\n",
    "                GREATEST(\n",
    "                    0,\n",
    "                    n.bias + SUM(e.weight * v.input_value)\n",
    "                ) AS value,\n",
    "                e.dst AS id\n",
    "            FROM edge e\n",
    "            JOIN input_nodes i ON i.id = e.src\n",
    "            JOIN node n ON e.dst = n.id\n",
    "            JOIN input_values v ON i.input_node_idx = v.input_node_idx\n",
    "            GROUP BY e.dst, n.bias, v.input_set_id\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- Recursive case\n",
    "            SELECT\n",
    "                tx.input_set_id AS input_set_id,\n",
    "                GREATEST(\n",
    "                    0,\n",
    "                    n.bias + SUM(e.weight * tx.value)\n",
    "                ) AS value,\n",
    "                e.dst AS id\n",
    "            FROM edge e\n",
    "            JOIN tx ON tx.id = e.src\n",
    "            JOIN node n ON e.dst = n.id\n",
    "            GROUP BY e.dst, n.bias, tx.input_set_id\n",
    "        ),\n",
    "        -- As the last step, repeat the calculation for the output nodes, but omit the\n",
    "        -- ReLU this time (per definition)\n",
    "        t_out AS (\n",
    "            SELECT\n",
    "                tx.input_set_id AS input_set_id,\n",
    "                n.bias + SUM(e.weight * tx.value) AS value,\n",
    "                e.dst AS output_node_id\n",
    "            FROM edge e\n",
    "            JOIN output_nodes o ON e.dst = o.id\n",
    "            JOIN node n ON o.id = n.id\n",
    "            JOIN tx ON tx.id = e.src\n",
    "            GROUP BY e.dst, n.bias, tx.input_set_id\n",
    "        )\n",
    "        SELECT * FROM t_out ORDER BY input_set_id, output_node_id;\n",
    "    \"\"\"\n",
    "\n",
    "    args = []\n",
    "    for input_set in input_value:\n",
    "        for value in input_set:\n",
    "            args.append(value)\n",
    "\n",
    "    results = [[] for _ in range(0, len(input_value))]\n",
    "    for row in db.con.execute(query, args).fetchall():\n",
    "        (input_set_id, output, output_node_id) = row\n",
    "        results[input_set_id].append(output)\n",
    "\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The results\n",
    "\n",
    "When we run this query, we can see that we achieve the same result as regular\n",
    "model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The neural network predicted [[-0.73033047  4.7305093   0.5392649  -0.9155848  -1.2634848   3.1685772 ]]\n",
      "The SQL query calculated [[-0.73033228  4.73051359  0.53926785 -0.91558373 -1.26348692  3.16857577]]\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.randn(1, input_size) * 100\n",
    "nn_output = model(test_input).detach().numpy()\n",
    "sql_output = eval_nn(test_input.tolist())\n",
    "\n",
    "print(f\"The neural network predicted {nn_output}\")\n",
    "print(f\"The SQL query calculated {sql_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We now have a way to evaluate a neural network in SQL without any prerequisite\n",
    "knowledge of the neural network. Note that this part was mostly informative. The\n",
    "FO(SUM) logic does not allow recursion, SQL is more powerful in that aspect.\n",
    "\n",
    "In the following chapter we'll try to replicate this result using a graph\n",
    "database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
